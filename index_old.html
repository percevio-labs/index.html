<!DOCTYPE html>
<html lang="en-us">
  <head>
    <link href="https://fonts.googleapis.com/css2?family=Merriweather:wght@300;400;700&family=Roboto:wght@400;500;700&display=swap" rel="stylesheet">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="generator" content="Source Themes Academic 4.8.0">
    <meta name="author" content="Muhammad Usama Saleem">
    <meta name="description" content="Graduate Student">
    <link rel="alternate" hreflang="en-us" href="https://m-usamasaleem.github.io/">
    <meta name="theme-color" content="#2962ff">
    <script src="/js/mathjax-config.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
    <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled> -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
    <link rel="stylesheet" href="/css/academic.css">
    <script src="https://identity.netlify.com/v1/netlify-identity-widget.js"></script>
    <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Muhammad Usama Saleem">
    <link rel="manifest" href="/index.webmanifest">
    <link rel="icon" type="image/png" href="/images/logo.jpg">
    <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_3.png">
    <link rel="canonical" href="https://m-usamasaleem.github.io/">
    <meta property="twitter:card" content="summary">
    <meta property="og:site_name" content="Muhammad Usama Saleem">
    <meta property="og:url" content="https://m-usamasaleem.github.io/">
    <meta property="og:title" content="Muhammad Usama Saleem">
    <meta property="og:description" content="Graduate Student">
    <meta property="og:image" content="https://m-usamasaleem.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png">
    <meta property="twitter:image" content="https://m-usamasaleem.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png">
    <meta property="og:locale" content="en-us">
    <meta property="og:updated_time" content="2022-05-17T16:00:00-04:00">
    <script type="application/ld+json">
      {
        "@context": "https://schema.org",
        "@type": "WebSite",
        "potentialAction": {
          "@type": "SearchAction",
          "target": "https://m-usamasaleem.github.io?q={search_term_string}",
          "query-input": "required name=search_term_string"
        },
        "url": "https://m-usamasaleem.github.io"
      }
    </script>
    <title>Muhammad Usama Saleem</title>
  </head>
  <style>
    .conference-name {
      color: #A6372A;
      font-style: italic;
      font-weight: normal;
      font-size: 1em;
    }

    #visitor-map {
      width: 100px;
      height: 100px;
      background: #f4f4f4;
      /* Light background */
      border: 1px solid #ddd;
      /* Add a subtle border */
      border-radius: 8px;
      /* Optional rounded corners */
      margin: 20px auto;
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
      /* Optional shadow for a modern look */
    }

    #fallback-message {
      text-align: center;
      font-size: 1.2em;
      color: #666;
      margin-top: 20px;
    }

    body {
      font-size: 80%;
      /* Decrease font size to 90% of the default size */
    }

    /* Custom link styling */
    a {
      color: #A6372A;
      /* Custom link color */
      text-decoration: none;
      /* Removes underline for a cleaner look */
    }

    a:hover {
      text-decoration: underline;
      /* Underline on hover for better accessibility */
    }

    /* Masthead */
    .masthead {
      height: 100vh;
      min-height: 500px;
      background-image: url('./website/head.jpg');
      background-size: cover;
      background-position: center;
      background-repeat: no-repeat;
      position: relative;
    }

    .masthead h1 {
      font-size: 3rem;
      color: white;
      text-shadow: 0 4px 6px rgba(0, 0, 0, 0.5);
      text-align: center;
      padding-top: 40%;
    }

    /* Media Queries */
    @media (max-width: 768px) {
      h1 {
        font-size: 2rem;
      }

      h2 {
        font-size: 1.5rem;
      }

      .masthead h1 {
        font-size: 2rem;
        padding-top: 50%;
      }
    }

    body {
      font-family: 'Roboto', Arial, sans-serif;
      background: linear-gradient(to bottom, #f8f9fa, #e9ecef);
    }

    h1,
    h2,
    h3 {
      font-family: 'Poppins', Arial, sans-serif;
      font-weight: 700;
    }

    a {
      font-family: 'Poppins', Arial, sans-serif;
      color: #A6372A;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    .responsive-padding {
      padding: 40px;
      /* Default padding */
    }

    @media (max-width: 768px) {
      .responsive-padding {
        padding: 20px;
        /* Smaller padding for tablets */
      }
    }

    @media (max-width: 576px) {
      .responsive-padding {
        padding: 10px;
        /* Smallest padding for mobile devices */
      }
    }

    body {
      font-family: 'Merriweather', serif;
      font-size: 1rem;
      /* ‚âà16px */
      line-height: 1.6;
      /* extra breathing room */
      color: #333;
      /* dark gray, softer than pure black */
      background-color: #fafafa;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      font-family: 'Roboto', sans-serif;
      font-weight: 500;
      color: #111;
      /* almost black for strong hierarchy */
      margin-top: 1.5em;
      margin-bottom: 0.5em;
    }

    p {
      margin-bottom: 1em;
    }

    ul,
    ol {
      margin-left: 1.5em;
      /* indent lists */
      margin-bottom: 1em;
    }

    .container {
      max-width: 960px;
      /* constrain line length to ~60‚Äì75ch */
      margin: 0 auto;
      padding: 0 1rem;
    }

    :root {
      --brand-color: #A6372A;
      /* a deeper, more subdued red */
      --accent-color: #555;
      /* for links and hover states */
    }

    a {
      color: var(--brand-color);
      text-decoration: none;
    }

    a:hover {
      color: var(--accent-color);
      text-decoration: underline;
    }

    section {
      padding: 3rem 0;
      border-bottom: 1px solid #e0e0e0;
    }

    section:last-of-type {
      border-bottom: none;
    }

    html {
      /* make 1rem equal to 14px instead of the browser default (~16px) */
      font-size: 87.5%;
      /* 16px * 0.875 = 14px */
    }

    /* Make the publications list 80% width and center it */
    #publications .pub-list {
      max-width: 90%;
      margin: 0 auto;
    }

    /* Space out each entry a bit */
    #publications .stream-item {
      margin-bottom: 2rem;
    }

    /* (Optional) Tweak the heading under this section */
    #publications h1 {
      margin-bottom: 2rem;
    }

    /* Place this **after** your default avatar styles */
    #profile .avatar.avatar-circle {
      width: 150px !important;
      /* or whatever fixed size you prefer */
      height: 150px !important;
      /* match width to keep it square */
      border-radius: 50% !important;
      /* ensure it's a perfect circle */
      object-fit: cover !important;
      /* crop/scale the image to fill the square */
    }

    .inline-logo {
      display: inline-flex;
      align-items: center;
      /* vertical-center everything */
      /*   margin: 0 0.5em;           /* small horizontal spacing */
      */
    }

    .inline-logo img {
      width: 20px;
      /* or whatever you prefer */
      height: auto;
      /*   margin-right: 4px;         /* space between logo and name */
      */
    }

    .inline-logo {
      display: inline-flex;
      align-items: center;
      /*     margin: 0 0.25em; */
    }

    .inline-logo img {
      width: 20px;
      height: auto;
    }

    .logo-name {
      font-weight: 700;
      color: #A6372A;
      /* your brand color */
      text-decoration: none;
      /*     margin: 0 0.25em; */
    }

    .logo-name:hover {
      text-decoration: underline;
    }

    /* tighten up the gap after your News list */
    #about .container>.row:last-of-type {
      margin-bottom: 1rem;
      /* was something much larger by default */
    }

    /* reduce the top‚Äêpadding of the Publications section */
    #publications {
      padding-top: 1.5rem !important;
      /* instead of the default 3rem */
    }

    /* if you still see too much space, also trim the section wrapper: */
    #publications .container {
      margin-top: 0;
    }

    #about.home-section {
      padding-top: 1.5rem !important;
      padding-bottom: 1.5rem !important;
    }

    /* narrow the default container gutters */
    #about .container {
      max-width: 960px;
      padding-left: 0.5rem;
      padding-right: 0.5rem;
    }

    /* shrink the avatar column */
    #about .col-lg-2 {
      max-width: 16.6667%;
      flex: 0 0 16.6667%;
    }

    /* slightly reduce h1 ‚Üí p spacing */
    #about h1 {
      margin-bottom: 0.5rem;
    }

    /* tighten the gap before Publications */
    #about .network-icon+h2,
    #about p+h2 {
      margin-top: 1.5rem;
    }

    /* style your bell icon */
    .news-icon {
      color: #A6372A;
      /* same brand red */
      margin-right: 0.5em;
      /* space between icon and date */
      font-size: 1em;
      /* match your text size */
    }

    /* style the company names */
    .logo-name {
      font-weight: 700;
      color: var(--brand-color);
      text-decoration: none;
      margin: 0 0.25em;
    }

    .logo-name:hover {
      text-decoration: underline;
    }

    .news-heading {
      display: flex;
      align-items: center;
      font-family: 'Roboto', sans-serif;
      margin-bottom: 0.5em;
    }

    .news-heading .news-icon {
      color: #A6372A;
      margin-left: 0.5em;
      font-size: 1.2em;
    }

    .news-list {
      font-size: 0.8em;
      list-style: none;
      padding-left: 0;
    }

    .news-list li {
      margin-bottom: 0.5em;
      line-height: 1.4;
    }

    .news-list .news-icon {
      color: #A6372A;
      margin-right: 0.25em;
    }

    .logo-name {
      font-weight: 700;
      color: #A6372A;
      text-decoration: none;
    }

    .logo-name:hover {
      text-decoration: underline;
    }

    /* constrain the publications list to ~80% width, centered */
    #publications .pub-list {
      max-width: 80%;
      margin: 0 auto;
    }

    #publications .stream-item.boxed {
      display: flex;
      flex-wrap: nowrap;
      position: relative;
      padding: 1.5rem;
      border: 1px solid #e0e0e0;
      border-radius: 8px;
      margin-bottom: 2rem;
      background: #fff;
    }

    /* Text area: leave space on the right for the thumbnail */
    #publications .stream-item.boxed .media-body {
      flex: 1 1 auto;
      padding-right: 180px;
      /* thumbnail width + gap */
    }

    /* Thumbnail/video */
    #publications .stream-item.boxed .thumbnail {
      position: absolute;
      top: 1.5rem;
      right: 1.5rem;
      width: 150px;
      height: 90px;
      border-radius: 4px;
      overflow: hidden;
      flex: 0 0 auto;
    }

    #publications .stream-item.boxed .thumbnail video {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }

    /* Headings & metadata */
    #publications .stream-item.boxed .article-title {
      margin: 0 0 0.25rem;
    }

    #publications .stream-item.boxed .conference-name {
      font-style: italic;
      color: #A6372A;
      margin-bottom: 0.75rem;
    }

    #publications .stream-item.boxed .stream-meta.article-metadata {
      font-size: 0.8em;
      margin-bottom: 1rem;
    }

    /* Summary */
    #publications .stream-item.boxed .media-summary {
      font-size: 0.8em;
      line-height: 1.5;
      margin-bottom: 1rem;
      color: #333;
    }

    /* Buttons */
    #publications .stream-item.boxed .btn-links a {
      margin-right: 0.5rem;
    }

    #publications .stream-item.boxed {
      transition: background-color 0.2s ease;
    }

    /* restore the hover ‚Äúhighlight‚Äù */
    #publications .stream-item.boxed:hover {
      background-color: rgba(166, 55, 42, 0.05);
    }

    /* Highlight style for June 2025 news items */
    .highlight-june-2025 {
      background-color: rgba(166, 55, 42, 0.08);
      border-left: 4px solid var(--brand-color);
      padding: 0.75em 1em;
      margin-bottom: 0.5em;
      border-radius: 4px;
    }

    #experience .experience-item {
      display: flex;
      align-items: center;
      margin-bottom: 2rem;
    }

    #experience .company-logo {
      flex: 0 0 80px;
      margin-right: 1.5rem;
    }

    #experience .company-logo img {
      width: 150px;
      /* or whatever full size you want */
      height: auto;
      /* preserve aspect ratio */
      max-width: none;
      /* override any library constraints */
    }

    #experience .experience-details h3 {
      margin-top: 0;
    }

    .experience-details p {
      display: inline-flex;
      align-items: baseline;
      /* keep text aligned nicely */
      gap: 2rem;
      /* space between location and dates */
      flex-wrap: wrap;
      /* in case it needs to wrap on small screens */
    }

    #experience .experience-details ul {
      margin: 0;
      padding-left: 1.25em;
    }

    #experience .container {
      padding: 3rem;
      border-radius: 8px;
    }

    /* match your publications & posts headings */
    #experience .section-heading h1 {
      margin-top: 1.5rem;
      /* same top spacing */
      margin-bottom: 2rem;
      /* same bottom spacing */
      font-size: 2.5rem;
      /* match your other 
																																	
																																
																																<h1> in .section-heading */
      text-align: left;
      /* override any stray centering */
      border-bottom: none;
      /* no extra lines */
    }

    #experience .container {
      background-color: #fff !important;
    }

    #experience.home-section {
      background-color: #fff;
    }

    /* 1) Make the entire Experience section pure white */
    #experience {
      background-color: #fff;
      /* tighten its top & bottom padding to match your other sections */
      padding-top: 1.5rem !important;
      padding-bottom: 1.5rem !important;
    }

    /* 2) Kill the section‚Äêborder ‚Äúhairlines‚Äù just above & below it */
    #experience,
    #experience+section {
      border-bottom: none !important;
    }

    /* 3) Reduce the huge gutters between sections */
    section {
      /* shrink the 3rem default to something tighter if you like */
      padding-top: 1.5rem;
      padding-bottom: 1.5rem;
    }

    /* 4) If your HTML is emitting extra 
																																		
																																	
																																	<hr> tags, hide them */
    hr {
      display: none;
    }

    /* 1) Make the page background pure white */
    body {
      background-color: #fff;
    }

    /* 2) Keep the Experience container itself white */
    #experience .container {
      background-color: #fff;
    }

    /* 3) Remove the horizontal ‚Äúborder‚Äù between Experience and the next section */
    section#experience {
      border-bottom: none;
    }

    /* 4) Match the padding of the other sections (you already have 1.5rem if you like it) */
    section#experience,
    section#experience+section {
      padding-top: 1.5rem;
      padding-bottom: 1.5rem;
    }

    /* 1) Shrink the default section padding a bit */
    section {
      padding-top: 2rem;
      /* was 3rem */
      padding-bottom: 2rem;
      /* was 3rem */
    }

    /* 2) If you want them even tighter only between Experience ‚Üí Publications */
    section#experience {
      padding-bottom: 1.5rem;
    }

    section#publications {
      padding-top: 1.5rem;
    }

    /* 3) Remove any extra hr or border from the bottom of #experience */
    section#experience {
      border-bottom: none;
      margin-bottom: 0;
      /* in case your theme adds extra space */
    }

    /* 4) Make sure headings don‚Äôt add huge margins */
    section h1 {
      margin-top: 0.5rem;
      margin-bottom: 1rem;
    }

    /* tighten vertical spacing */
    section {
      padding: 2rem 0;
    }

    section#experience {
      padding-bottom: 1.5rem;
      border-bottom: none;
      margin-bottom: 0;
    }

    /* center and constrain work experience */
    #experience .container {
      max-width: 800px;
      margin: 0 auto;
      padding: 0 1rem;
    }

    /* heading margins */
    #experience h1 {
      margin: 0.5rem 0 1rem;
    }
  </style>
  <aside class="search-results" id="search">
    <div class="container">
      <section class="search-header">
        <div class="row no-gutters justify-content-between mb-3">
          <div class="col-6">
            <h1>Search</h1>
          </div>
          <div class="col-6 col-search-close">
            <a class="js-search" href="#">
              <i class="fas fa-times-circle text-muted" aria-hidden="true"></i>
            </a>
          </div>
        </div>
        <div id="search-box">
          <input name="q" id="search-query" placeholder="Search..." autocapitalize="off" autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control">
        </div>
      </section>
      <section class="section-search-results">
        <div id="search-hits"></div>
      </section>
    </div>
  </aside>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container">
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Muhammad Usama Saleem</a>
      </div>
      <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span>
          <i class="fas fa-bars"></i>
        </span>
      </button>
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Muhammad Usama Saleem</a>
      </div>
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">
        <ul class="navbar-nav d-md-inline-flex">
          <li class="nav-item">
            <a class="nav-link " href="/#about" data-target="#about">
              <span>Home</span>
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link " href="/#publications" data-target="#publications">
              <span>Research</span>
            </a>
          </li>
          <!-- <li class="nav-item"><a class="nav-link " href="/#experience" data-target="#experience"><span>Experience</span></a></li> -->
          <!-- <li class="nav-item"><a class="nav-link " href="/#projects" data-target="#projects"><span>Projects</span></a></li> -->
          <!-- <li class="nav-item"><a class="nav-link " href="/#posts" data-target="#posts"><span>Posts</span></a></li> -->
        </ul>
      </div>
      <!-- <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item"><a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a></li><li class="nav-item dropdown theme-dropdown"><a href="#" class="nav-link js-theme-selector" data-toggle="dropdown" aria-haspopup="true"><i class="fas fa-palette" aria-hidden="true"></i></a><div class="dropdown-menu"><a href="#" class="dropdown-item js-set-theme-light"><span>Light</span></a><a href="#" class="dropdown-item js-set-theme-dark"><span>Dark</span></a><a href="#" class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul> -->
      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search">
            <i class="fas fa-search" aria-hidden="true"></i>
          </a>
        </li>
      </ul>
    </div>
  </nav>
  <span class="js-widget-page d-none"></span>
  <section id="about" class="home-section wg-about">
    <div class="container">
      <div class="row">
        <!-- shrink avatar column to give more room for text -->
        <div class="col-12 col-lg-3">
          <div id="profile">
            <img class="avatar avatar-circle" src="/author/usama/image.jpeg" alt="Muhammad Usama Saleem">
            <div class="portrait-title">
              <h2>Muhammad Usama Saleem</h2>
              <h3>Ph.D. Student</h3>
              <h3>
                <span>University of North Carolina at Charlotte</span>
              </h3>
            </div>
            <ul class="network-icon" aria-hidden="true">
              <li>
                <a href="mailto:msaleem2@charlotte.edu">
                  <i class="fas fa-envelope big-icon"></i>
                </a>
              </li>
              <li>
                <a href="https://scholar.google.com/citations?user=8ZSRk3IAAAAJ&hl" target="_blank" rel="noopener">
                  <i class="ai ai-google-scholar big-icon"></i>
                </a>
              </li>
              <li>
                <a href="https://github.com/m-usamasaleem" target="_blank" rel="noopener">
                  <i class="fab fa-github big-icon"></i>
                </a>
              </li>
              <li>
                <a href="https://www.linkedin.com/in/muhammad-usama-saleem-504b65164" target="_blank" rel="noopener">
                  <i class="fab fa-linkedin big-icon"></i>
                </a>
              </li>
              <li>
                <a href="https://x.com/usamasaleem_" target="_blank" rel="noopener">
                  <i class="fab fa-twitter big-icon"></i>
                </a>
              </li>
            </ul>
          </div>
        </div>
        <!-- expand text column -->
        <div class="col-12 col-lg-9">
          <h1>About me</h1>
          <p> I am a Ph.D. candidate in Computer Science at the University of North Carolina at Charlotte, supervised by <strong>
              <a href="https://scholar.google.com/citations?hl=en&user=0buJlAUAAAAJ" target="_blank">Dr. Pu Wang</a>
            </strong> in the GENIUS Lab. In industry, I work as a researcher with the Computer Vision teams at <span class="inline-logo">
              <a href="https://www.amazon.com/" target="_blank">
                <img src="/author/usama/az.webp" alt="Amazon logo">
              </a>
            </span>
            <!-- Amazon name separately -->
            <a href="https://www.amazon.com/" target="_blank" class="logo-name">Amazon</a> and
            <!-- Lowe‚Äôs logo only -->
            <span class="inline-logo">
              <a href="https://www.lowes.com/" target="_blank">
                <img src="/author/usama/lowes.png" alt="Lowe‚Äôs logo">
              </a>
            </span>
            <!-- Lowe‚Äôs name separately -->
            <a href="https://www.lowes.com/" target="_blank" class="logo-name">Lowe‚Äôs</a> where I am developing large-scale, multimodal language models (MLLMs) to enhance operational efficiency and customer experience in complex, real-world environments. Moreover, I joined <span class="inline-logo">
              <a href="https://www.google.com/" target="_blank">
                <img src="/author/usama/google.png" alt="Google logo">
              </a>
            </span>
            <a href="https://www.google.com/" target="_blank" class="logo-name">Google</a> as a Student Researcher in the Extended Reality (AR/VR) team, working on advancing multimodal and generative AI for immersive technologies.
          </p>
          <!--
        <p>I am currently a Ph.D. candidate in the Department of Computer Science at the <strong><a href="https://www.charlotte.edu/" target="_blank">University of North Carolina at Charlotte</a></strong>, working under the supervision of <span style="color: #A6372A;"><strong><a href="https://scholar.google.com/citations?hl=en&user=0buJlAUAAAAJ&view_op=list_works&authuser=2&sortby=pubdate" target="_blank">Dr. Pu Wang</a></strong></span> at the <span style="color: #A6372A;"><em><a href="" target="_blank">GENIUS Lab</a></em></span>. My research focuses on advancing computer vision and generative AI, particularly in <strong>3D Human Pose Estimation</strong> and <strong>Mesh Recovery</strong>. Moreover, I am interested in <strong>3D Human Motion Generation</strong> driven by multi-modal inputs (e.g., text, music, or speech), with a focus on achieving controllable, high-quality synthesis for realistic and dynamically responsive motion generation in real-time interactive settings. Previously, at the <span style="color: #A6372A;"><em><a href="https://webpages.charlotte.edu/lfan4/index.html" target="_blank">Image Privacy Lab</a></em></span> under <span style="color: #A6372A;"><strong><a href="https://scholar.google.com/citations?hl=en&user=mPJmXakAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Dr. Liyue Fan</a></strong></span>, I developed privacy-preserving federated frameworks for generative AI, enabling secure synthetic data generation in non-IID settings. Currently, I am a researcher at Amazon and Lowe‚Äôs working on computer vision and generative AI. Before joining UNCC, I earned my Bachelor's degree in Computer Science from <strong><a href="https://_"></a></strong></p>
        -->
          <h2>Research Interests</h2>
          <p> My research interests lie at the intersection of computer vision and generative AI, with a focus on 3D human modeling. Specifically, I focus on 3D human pose estimation and mesh reconstruction via generative masked modeling. Moreover, I‚Äôm interested in developing multimodal motion synthesis frameworks that synthesize controllable, high-fidelity 3D human animations for real time applications. </p>
          <p>
            <strong> If you have any research opportunities or open positions, please feel free to reach out at <a href="mailto:msaleem2@charlotte.edu" style="color: #A6372A;">
                <em>msaleem2@charlotte.edu</em>
              </a>. </strong>
          </p>
          <!--  In parallel, I‚Äôm building large-scale multimodal language models to enable robust video understanding in complex, real-world environments. -->
          <!--
        <p> My research interests lie in Computer Vision and Generative AI, specifically focusing on two interconnected pillars: </p><ul><li>3D Human Pose Estimation and Mesh Recovery</li><li>Multi-Modality Motion Synthesis</li></ul>
        -->
          <h3 class="news-heading">
            <i class="fas fa-bell news-icon" aria-hidden="true"></i> News
          </h3>
          <ul class="news-list">

            <li class="highlight-june-2025">
              <i class="fas fa-bell news-icon" aria-hidden="true"></i>
              <strong>Nov 2025:</strong> ‚ÄúLiveGesture: Streamable Co-Speech Gesture Generation Model‚Äù will be available on <strong style="color:#A6372A">arXiv</strong>!
            </li>
            <li class="highlight-june-2025">
              <i class="fas fa-bell news-icon" aria-hidden="true"></i>
              <strong>Nov 2025:</strong> ‚ÄúMonocular Models are Strong Learners for Multi-View Human Mesh Recovery‚Äù will be available on <strong style="color:#A6372A">arXiv</strong>!
            </li>
			  
            <li class="highlight-june-2025">
              <i class="fas fa-bell news-icon" aria-hidden="true"></i>
              <strong>Nov 2025:</strong> ‚ÄúWalk Before You Dance: High-fidelity and Editable Dance Synthesis via Generative Masked Motion Prior‚Äù was accepted to <strong style="color:#A6372A">AAAI 2026</strong>!
            </li>
            <li class="highlight-june-2025">
              <i class="fas fa-bell news-icon" aria-hidden="true"></i>
              <strong>October 2025:</strong> Joined <a href="https://www.google.com/" target="_blank" class="logo-name">Google</a> as Student Researcher in Extended Reality (AR/VR) Team!
            </li>
            <li class="highlight-june-2025">
              <i class="fas fa-bell news-icon" aria-hidden="true"></i>
              <strong>October 2025:</strong> MaskControl paper selected for <em>Oral Presentation</em> and <em>üèÜ Award Candidate</em> at <strong style="color:#A6372A">ICCV 2025</strong>!
            </li>
            <li class="highlight-june-2025">
              <i class="fas fa-bell news-icon" aria-hidden="true"></i>
              <strong>Aug 2025:</strong> Available for <span class="logo-name">Research Scientist / Engineer</span> oppertunities. Please reach out if there‚Äôs a good match.
            </li>
            <li class="highlight-june-2025">
              <i class="fas fa-bell news-icon" aria-hidden="true"></i>
              <strong>July 2025:</strong> Poster selected at <em> Amazon WWAS Science Fair Seattle</em>, presented next-gen multimodal shopping demo to VPs!
            </li>
            <li class="highlight-june-2025">
              <i class="fas fa-bell news-icon" aria-hidden="true"></i>
              <strong>June 2025:</strong> Joined <a href="https://www.amazon.com/" target="_blank" class="logo-name">Amazon</a> as Applied Scientist II Intern
            </li>
            <li class="highlight-june-2025">
              <i class="fas fa-bell news-icon" aria-hidden="true"></i>
              <strong>June 2025:</strong> A paper on ‚ÄúMaskHand: Generative Masked Modeling for Robust Hand Mesh Reconstruction in the Wild‚Äù is accepted to <strong style="color:#A6372A">ICCV 2025</strong>!
            </li>
            <li class="highlight-june-2025">
              <i class="fas fa-bell news-icon" aria-hidden="true"></i>
              <strong>June 2025:</strong> A paper on ‚ÄúSpatio-Temporal Control for Masked Motion Synthesis‚Äù is accepted to <strong style="color:#A6372A">ICCV 2025 (Oral)</strong>!
            </li>
            <li>
              <strong>April 2025:</strong> ‚ÄúWalk Before You Dance: High-fidelity and Editable Dance Synthesis via Generative Masked Motion Prior‚Äù is now available on <strong style="color:#A6372A">arXiv</strong>.
            </li>
            <li>
              <strong>Dec 2024:</strong> ‚ÄúGenHMR: Generative Human Mesh Recovery‚Äù was accepted to <strong style="color:#A6372A">AAAI 2025</strong>, presented in Philadelphia, and received a travel award.
            </li>
            <li>
              <strong>Oct 2024:</strong> ‚ÄúBioPose: Biomechanically-Accurate 3D Pose Estimation from Monocular Videos‚Äù is accepted to <strong style="color:#A6372A">WACV 2025</strong>!
            </li>
            <li>
              <strong>July 2024:</strong> ‚ÄúBAMM: Bidirectional Autoregressive Motion Model‚Äù is accepted to <strong style="color:#A6372A">ECCV 2024</strong>!
            </li>
            <li>
              <i class="fas fa-bell news-icon" aria-hidden="true"></i>
              <strong>Sept 2023:</strong> Joined <a href="https://www.lowes.com/" target="_blank" class="logo-name">Lowe‚Äôs</a> as Research Lead of the Computer Vision UNCC Team
            </li>
            <li>
              <strong>June 2023:</strong> ‚ÄúPrivate Data Synthesis from Decentralized Non-IID Data‚Äù accepted to <strong style="color:#A6372A">IJCNN 2023</strong>, presented in Queensland, Australia, and received a $5500 travel grant!
            </li>
            <li>
              <strong>April 2023:</strong> Presented at the <strong style="color:#A6372A">SIAM International Conference on Data Mining (SDM‚Äô23)</strong> Doctoral Forum; awarded NSF $1400 travel grant.
            </li>
            <li>
              <strong>July 2022:</strong> ‚ÄúPrivacy Enhancement for Cloud-Based Few-Shot Learning‚Äù accepted to <strong style="color:#A6372A">IJCNN 2022</strong>!
            </li>
            <li>
              <strong>Jan 2022:</strong> ‚ÄúDP-Shield: Face Obfuscation with Differential Privacy‚Äù accepted to <strong style="color:#A6372A">EDBT 2022</strong>!
            </li>
          </ul>
        </div>
      </div>
    </div>
  </section>
  <!-- <section id="skills" class="home-section wg-featurette   "><div class="container"><div class="row featurette"><div class="col-md-12 section-heading"><h1>Skills</h1></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/python.svg" alt="python" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/C.svg" alt="C" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/cplusplus.svg" alt="cplusplus" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/csharp.svg" alt="csharp" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/java.svg" alt="java" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/matlab.svg" alt="matlab" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/scala.svg" alt="scala" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/mysql.svg" alt="mysql" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/bash.svg" alt="bash" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/latex.svg" alt="latex" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/R.svg" alt="R" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/haskell.svg" alt="haskell" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/docker.svg" alt="docker" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/git.svg" alt="git" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/jupyter.svg" alt="jupyter" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/numpy.svg" alt="numpy" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/opencv.svg" alt="opencv" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/pandas.svg" alt="pandas" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/pytorch.svg" alt="pytorch" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/scikit.svg" alt="scikit" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/tensorflow.svg" alt="tensorflow" class="svg-icon svg-baseline"></div><h3></h3></div><div class="col-12 col-sm-2"><div class="featurette-icon"><img src="/images/icon-pack/huggingface.svg" alt="huggingface" class="svg-icon svg-baseline"></div><h3></h3></div></div></div></section> -->
  <section id="experience" class="home-section wg-pages">
    <div class="container">
      <div class="row">
        <div class="col-12">
          <h1 class="text-center">Work Experience</h1>
        </div>
      </div>
      <div class="row">
        <div class="col-12">
          <div class="experience-item">
            <div class="company-logo">
              <img src="./author/usama/google.png" alt="Google logo" width="200">
            </div>
            <div class="experience-details">
              <h3>Student Researcher at Extended Reality (AR/VR) Team</h3>
              <p>
                <span class="company-location">
                  <strong>Google</strong>, San Francisco, CA </span>
                <span class="employment-dates"> Nov. 2025 ‚Äì Present </span>
              </p>
            </div>
          </div>
          <div class="experience-item">
            <div class="company-logo">
              <img src="./author/usama/amazon.webp" alt="Amazon logo" width="200">
            </div>
            <div class="experience-details">
              <h3>Applied Scientist II Intern</h3>
              <p>
                <span class="company-location">
                  <strong>Amazon Inc.</strong>, Boston, MA </span>
                <span class="employment-dates"> June 2025 ‚Äì Present </span>
              </p>
            </div>
          </div>
          <div class="experience-item">
            <div class="company-logo">
              <img src="./author/usama/lowes.png" alt="Lowe‚Äôs logo" width="200">
            </div>
            <div class="experience-details">
              <h3>Research Lead, Computer Vision UNCC Team</h3>
              <p>
                <span class="company-location">
                  <strong>Lowe‚Äôs</strong>, Charlotte, NC </span>
                <span class="employment-dates"> Sept. 2023 ‚Äì Present </span>
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <section id="publications" class="home-section wg-pages">
    <div class="container">
      <!-- Full-width heading -->
      <div class="row">
        <div class="col-12">
          <h1 class="text-center">Recent Publications</h1>
        </div>
      </div>
      <!-- Centered list at 80% width -->
      <div class="row">
        <div class="col-12">
          <div class="pub-list mx-auto">
            <div class="media stream-item boxed">
              <div class="media-body">
                <h4 class="article-title mb-1">
                  <a href="https://m-usamasaleem.github.io/"> LiveGesture: Streamable Co-Speech Gesture Generation Model </a>
                </h4>
                <div class="conference-name">
                  <strong>arXiv</strong>
                </div>
                <div class="stream-meta article-metadata mb-2"> <strong>
                    <u>Muhammad Usama Saleem</u>
                  </strong>, Mayur Jagdishbhai Patel, Ekkasit Pinyoanuntapong, Zhongxing Qin, Li Yang, Hongfei Xue, Ahmed Helmy, Chen Chen, Pu Wang </div>
                <!-- <div class="mb-3" style="font-weight: bold; color: #A6372A; font-size: 0.85em;"> *Equal Contribution </div> -->
                <div class="media-summary">LiveGesture is the first fully streamable, zero‚Äìlook-ahead co-speech gesture generation framework that produces expressive, region-coordinated full-body motion in real time using a causal SVQ tokenizer and hierarchical autoregressive transformers. </div>
                <div class="btn-links mb-4">
                  <a class="btn btn-outline-primary btn-sm mr-2" href="./publication/LiveGesture/LiveGesture.html" target="_blank">PDF</a>
                  <a class="btn btn-outline-primary btn-sm" href="./publication/LiveGesture/LiveGesture.html" target="_blank">Webpage</a>
                </div>
              </div>
              <div class="thumbnail">
                <img src="/author/usama/LiveGesture.png" alt="LiveGesture thumbnail" style="width:100%; height:100%; object-fit:cover;">
              </div>
            </div>
            <!-- DanceMosaic -->
            <div class="media stream-item boxed">
              <div class="media-body">
                <h4 class="article-title mb-1">
                  <a href="https://foram-s1.github.io/DanceMosaic/"> Walk Before You Dance: High-fidelity and Editable Dance Synthesis via Generative Masked Motion Prior </a>
                </h4>
                <div class="conference-name">
                  <strong>AAAI 2026</strong>
                </div>
                <div class="stream-meta article-metadata mb-2"> Foram Shah*, Parshwa Shah*, <strong>
                    <u>Muhammad Usama Saleem</u>
                  </strong>, Ekkasit Pinyoanuntapong, Pu Wang, Hongfei Xue, Ahmed Helmy </div>
                <div class="mb-3" style="font-weight: bold; color: #A6372A; font-size: 0.85em;"> *Equal Contribution </div>
                <div class="media-summary"> DanceMosaic is a novel multimodal masked motion framework‚Äîfusing text, music, and pose adapters via progressive generative masking with inference-time optimization for precise, editable motion. </div>
                <div class="btn-links mb-4">
                  <a class="btn btn-outline-primary btn-sm mr-2" href="https://arxiv.org/abs/2504.04634" target="_blank">PDF</a>
                  <a class="btn btn-outline-primary btn-sm" href="https://foram-s1.github.io/DanceMosaic/" target="_blank">Webpage</a>
                </div>
              </div>
              <div class="thumbnail">
                <video autoplay loop muted playsinline>
                  <source src="./videos/DanceMosaic.mkv" type="video/mp4">
                </video>
              </div>
            </div>
            <!-- MaskHand -->
            <div class="media stream-item boxed">
              <div class="media-body">
                <h4 class="article-title">
                  <a href="./publication/MaskHand/MaskHand.html"> MaskHand: Generative Masked Modeling for Robust Hand Mesh Reconstruction in the Wild </a>
                </h4>
                <div class="conference-name">
                  <strong>ICCV 2025</strong>
                </div>
                <div class="stream-meta article-metadata">
                  <strong>
                    <u>Muhammad Usama Saleem</u>
                  </strong>, Ekkasit Pinyoanuntapong, Mayur Jagdishbhai Patel, Hongfei Xue, Ahmed Helmy, Srijan Das, Pu Wang
                </div>
                <div class="media-summary"> MaskHand is a probabilistic masked modeling framework‚Äîtokenizing articulations with VQ-MANO and using a context-aware masked transformer to fuse multi-scale image features and 2D cues for iterative, confidence-guided sampling. </div>
                <div class="btn-links">
                  <a class="btn btn-outline-primary btn-sm" href="https://arxiv.org/abs/2412.13393" target="_blank">PDF</a>
                  <a class="btn btn-outline-primary btn-sm" href="./publication/MaskHand/MaskHand.html" target="_blank">Webpage</a>
                </div>
              </div>
              <div class="thumbnail">
                <video autoplay loop muted playsinline>
                  <source src="./videos/mmhmr.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            <!-- ControlMM -->
            <div class="media stream-item boxed">
              <div class="media-body">
                <h4 class="article-title">
                  <a href="https://exitudio.github.io/ControlMM-page/"> MaskControl: Spatio-Temporal Control for Masked Motion Synthesis </a>
                </h4>
                <div class="conference-name">
                  <strong>ICCV 2025 (Oral)</strong>
                </div>
                <div class="stream-meta article-metadata"> Ekkasit Pinyoanuntapong, <strong>
                    <u>Muhammad Usama Saleem</u>
                  </strong>, Korrawe Karunratanakul, Pu Wang, Hongfei Xue, Chen Chen, Chuan Guo, Junli Cao, Jian Ren, Sergey Tulyakov </div>
                <div class="media-summary"> MaskControl is a novel masked generative motion model‚Äîcombining masked consistency and inference-time logit editing in a parallel decoder for fast, high-fidelity, spatially precise motion generation. </div>
                <div class="btn-links">
                  <a class="btn btn-outline-primary btn-sm" href="https://arxiv.org/pdf/2410.10780" target="_blank">PDF</a>
                  <a class="btn btn-outline-primary btn-sm" href="https://exitudio.github.io/ControlMM-page/" target="_blank">Webpage</a>
                  <a class="btn btn-outline-primary btn-sm" href="https://github.com/exitudio/ControlMM" target="_blank">Code</a>
                </div>
              </div>
              <div class="thumbnail">
                <video autoplay loop muted playsinline>
                  <source src="./videos/CAM.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            <!-- GenHMR -->
            <div class="media stream-item boxed">
              <div class="media-body">
                <h4 class="article-title">
                  <a href="./publication/GenHMR/GenHMR.html"> GenHMR: Generative Human Mesh Recovery </a>
                </h4>
                <div class="conference-name">
                  <strong>AAAI 2025</strong>
                </div>
                <div class="stream-meta article-metadata">
                  <strong>
                    <u>Muhammad Usama Saleem</u>
                  </strong>, Ekkasit Pinyoanuntapong, Pu Wang, Hongfei Xue, Srijan Das, Chen Chen
                </div>
                <div class="media-summary"> GenHMR reframes monocular HMR as an image-conditioned generative task‚Äîemploying a VQ-VAE pose tokenizer and masked transformer to model 2D‚Üí3D uncertainty, iteratively sampling high-confidence tokens and refining them with 2D cues for accurate mesh recovery. </div>
                <div class="btn-links">
                  <a class="btn btn-outline-primary btn-sm" href="https://arxiv.org/abs/2412.14444" target="_blank">PDF</a>
                  <a class="btn btn-outline-primary btn-sm" href="./publication/GenHMR/GenHMR.html" target="_blank">Webpage</a>
                </div>
              </div>
              <div class="thumbnail">
                <video autoplay loop muted playsinline>
                  <source src="./videos/genhmr.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            <!-- BioPose -->
            <div class="media stream-item boxed">
              <div class="media-body">
                <h4 class="article-title">
                  <a href="./publication/BioPose/BioPose.html"> BioPose: Biomechanically-accurate 3D Pose Estimation from Monocular Videos </a>
                </h4>
                <div class="conference-name">
                  <strong>WACV 2025</strong>
                </div>
                <div class="stream-meta article-metadata">
                  <strong>
                    <u>Muhammad Usama Saleem*</u>
                  </strong>, Farnoosh Koleini*, Pu Wang, Hongfei Xue, Ahmed Helmy, Abbey Fenwick
                </div>
                <div class="media-summary"> BioPose is a novel biomechanics-guided 3D pose estimation framework‚Äîcombining a multi-query deformable transformer for precise mesh recovery, a neural IK network that enforces anatomical constraints, and 2D-informed iterative pose refinement. </div>
                <div class="btn-links">
                  <a class="btn btn-outline-primary btn-sm" href="https://arxiv.org/abs/2501.07800" target="_blank">PDF</a>
                  <a class="btn btn-outline-primary btn-sm" href="./publication/BioPose/BioPose.html" target="_blank">Webpage</a>
                </div>
              </div>
              <div class="thumbnail">
                <video autoplay loop muted playsinline>
                  <source src="./videos/biopose.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            <!-- BAMM -->
            <div class="media stream-item boxed">
              <div class="media-body">
                <h4 class="article-title mb-1">
                  <a href="https://exitudio.github.io/BAMM-page/"> BAMM: Bidirectional Autoregressive Motion Model </a>
                </h4>
                <div class="conference-name">
                  <strong>ECCV 2024</strong>
                </div>
                <div class="stream-meta article-metadata mb-3"> Ekkasit Pinyoanuntapong, <strong>
                    <u>Muhammad Usama Saleem</u>
                  </strong>, Pu Wang, Minwoo Lee, Srijan Das, Chen Chen </div>
                <div class="media-summary"> BAMM is a novel text-to-motion framework that employs a hybrid-masked self-attention transformer‚Äîmerging generative masking with autoregression to handle dynamic sequence lengths and enable editable, high-quality motion. </div>
                <div class="btn-links mb-4">
                  <a class="btn btn-outline-primary btn-sm mr-2" href="https://arxiv.org/abs/2403.19435" target="_blank">PDF</a>
                  <a class="btn btn-outline-primary btn-sm mr-2" href="https://exitudio.github.io/BAMM-page/" target="_blank">Webpage</a>
                  <a class="btn btn-outline-primary btn-sm" href="https://github.com/exitudio/BAMM/" target="_blank">Code</a>
                </div>
              </div>
              <div class="thumbnail">
                <video autoplay loop muted playsinline>
                  <source src="./videos/BAMM.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            <!-- Private Data Synthesis -->
            <div class="media stream-item boxed">
              <div class="media-body">
                <h4 class="article-title mb-1">
                  <a href="./publication/DPFedProxGAN/dpfedproxgan.html"> Private Data Synthesis from Decentralized Non-IID Data </a>
                </h4>
                <div class="conference-name">
                  <strong>IJCNN 2023</strong>
                </div>
                <div class="stream-meta article-metadata mb-3">
                  <strong>
                    <u>Muhammad Usama Saleem</u>
                  </strong>, L. Fan
                </div>
                <div class="media-summary"> DPFedProxGAN is a federated, differentially-private GAN that generates realistic synthetic images from non-IID distributed data using local DP and FedProx optimization. </div>
                <div class="btn-links mb-4">
                  <a class="btn btn-outline-primary btn-sm mr-2" href="https://ieeexplore.ieee.org/document/10191553" target="_blank">PDF</a>
                  <a class="btn btn-outline-primary btn-sm mr-2" href="./publication/DPFedProxGAN/Private_Data_Synthesis_from_Decentralized_Non_IID_Data_with_Appendix_IJCNN_23.pdf" target="_blank">Supplementary</a>
                  <a class="btn btn-outline-primary btn-sm" href="./publication/DPFedProxGAN/dpfedproxgan.html" target="_blank">Webpage</a>
                </div>
              </div>
              <div class="thumbnail">
                <img src="/publication/06-fs-data-synthesis/private_data.png" alt="Private Data Synthesis">
              </div>
            </div>
            <!-- Privacy Enhancement for Cloud-Based Few-Shot Learning -->
            <div class="media stream-item boxed">
              <div class="media-body">
                <h4 class="article-title mb-1">
                  <a href="/publication/05-fs-privacy/"> Privacy Enhancement for Cloud-Based Few-Shot Learning </a>
                </h4>
                <div class="conference-name">
                  <strong>IJCNN 2022</strong>
                </div>
                <div class="stream-meta article-metadata mb-3"> A. Parnami, <strong>
                    <u>Muhammad Usama Saleem</u>
                  </strong>, L. Fan, M. Lee </div>
                <div class="media-summary"> A novel few-shot framework uses a joint privacy‚Äìclassification loss to learn embeddings that protect image data while maintaining high few-shot accuracy in cloud-based vision. </div>
                <div class="btn-links mb-4">
                  <a class="btn btn-outline-primary btn-sm" href="https://arxiv.org/abs/2205.07864" target="_blank">PDF</a>
                </div>
              </div>
              <div class="thumbnail">
                <img src="/publication/05-fs-privacy/featured_hu5afa6d22d114b7460f804b57e93d75ca_82188_150x0_resize_lanczos_3.png" alt="Privacy Enhancement">
              </div>
            </div>
            <!-- DP-Shield: Face Obfuscation with Differential Privacy -->
            <div class="media stream-item boxed">
              <div class="media-body">
                <h4 class="article-title mb-1">
                  <a href="http://3.223.148.187/"> DP-Shield: Face Obfuscation with Differential Privacy </a>
                </h4>
                <div class="conference-name">
                  <strong>EDBT 2022</strong>
                </div>
                <div class="stream-meta article-metadata mb-3">
                  <strong>
                    <u>Muhammad Usama Saleem</u>
                  </strong>, D. Reilly, L. Fan
                </div>
                <div class="media-summary"> DP-Shield safeguards against unauthorized face recognition by applying differential privacy‚Äìbased obfuscation and providing image quality and recognition-risk metrics. </div>
                <div class="btn-links mb-4">
                  <a class="btn btn-outline-primary btn-sm mr-2" href="https://openproceedings.org/2022/conf/edbt/paper-150.pdf" target="_blank">PDF</a>
                  <a class="btn btn-outline-primary btn-sm mr-2" href="http://3.223.148.187/" target="_blank">Webpage</a>
                  <a class="btn btn-outline-primary btn-sm" href="https://github.com/m-usamasaleem/DP-Shield-EDBT-22" target="_blank">Code</a>
                </div>
              </div>
              <div class="thumbnail">
                <video style="width:150px; height:90px; object-fit:cover;" autoplay loop muted playsinline>
                  <source src="./videos/edbt.webm" type="video/mp4">
                </video>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- <section id="posts" class="home-section wg-pages   "> -->
  <!-- <div class="container"> -->
  <!-- <div class="row"><div class="col-12 col-lg-4 section-heading"><h1>Recent Posts</h1></div><div class="col-12 col-lg-8"><div class="media stream-item"><div class="media-body"><h3 class="article-title mb-0 mt-0"><a href="/post/laplacian-fsl/">Laplacian Regularized Few-Shot Learning</a></h3><a href="/post/laplacian-fsl/" class="summary-link"><div class="article-style"> Paper https://arxiv.org/abs/2006.15486 Code
                  https://github.com/imtiazziko/LaplacianShot Main Idea Transfer Learning: Image embeddings are obtained
                  by pre-training a network on the set of base classes using cross-entropy loss. </div></a><div class="stream-meta article-metadata"><div class="article-metadata"><div><span><a href="/author/usama/">Muhammad Usama Saleem</a></span></div><span class="article-date"> Aug 3, 2020 </span><span class="middot-divider"></span><span class="article-reading-time"> 2 min read </span><span class="middot-divider"></span><span class="article-categories"><i class="fas fa-folder mr-1"></i><a href="/category/Machine Learning/">Machine Learning</a></span></div></div></div><div class="ml-3"></div></div></div></div> -->
  <!-- </div> -->
  <!-- </section> -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.4.8/mermaid.min.js" integrity="sha256-lyWCDMnMeZiXRi7Zl54sZGKYmgQs4izcT7+tKc+KUBk=" crossorigin="anonymous" title="mermaid"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
  <script>
    const code_highlighting = true;
  </script>
  <script>
    const isSiteThemeDark = false;
  </script>
  <script>
    const search_config = {
      "indexURI": "/index.json",
      "minLength": 1,
      "threshold": 0.3
    };
    const i18n = {
      "no_results": "No results found",
      "placeholder": "Search...",
      "results": "results found"
    };
    const content_type = {
      'post': "Posts",
      'project': "Projects",
      'publication': "Publications",
      'talk': "Talks",
      'slides': "Slides"
    };
  </script>
  <script id="search-hit-fuse-template" type="text/x-template"> <div class="search-hit" id="summary-{{key}}">
																																																					<div class="search-hit-content">
																																																						<div class="search-hit-name">
																																																							<a href="{{relpermalink}}">{{title}}</a>
																																																							<div class="article-metadata search-hit-type">{{type}}</div>
																																																							<p class="search-hit-description">{{snippet}}</p>
																																																						</div>
																																																					</div>
																																																				</div>
																																																			</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
  <script>
    if (window.netlifyIdentity) {
      window.netlifyIdentity.on("init", user => {
        if (!user) {
          window.netlifyIdentity.on("login", () => {
            document.location.href = "/admin/";
          });
        }
      });
    }
  </script>
  <script src="/js/academic.min.341e58d06db179e1d53f3322b6883f4c.js"></script>
  <div class="container">
    <div id="visitor-map">
      <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=8PZR3rhBAnuOEFb9RecojjlYPmyeuvZ7B5cY31wCebE&cl=ffffff&w=a"></script>
      <noscript>
        <div id="fallback-message"> Visitor map cannot be displayed because JavaScript is disabled in your browser. </div>
      </noscript>
    </div>
    <footer class="site-footer">
      <p class="powered-by">
        <a href="/tag/privacy/">Privacy</a>
      </p>
      <p class="powered-by"> @2022 Muhammad Usama Saleem. All Rights Reserved. </p>
      <span class="float-right" aria-hidden="true">
        <a href="#" class="back-to-top">
          <span class="button_icon">
            <i class="fas fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>
    </footer>
  </div>
  <div id="modal" class="modal fade" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <h5 class="modal-title">Cite</h5>
          <button type="button" class="close" data-dismiss="modal" aria-label="Close">
            <span aria-hidden="true">&times;</span>
          </button>
        </div>
        <div class="modal-body">
          <pre>
																																																								<code class="tex hljs"></code>
																																																							</pre>
        </div>
        <div class="modal-footer">
          <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
            <i class="fas fa-copy"></i> Copy </a>
          <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
            <i class="fas fa-download"></i> Download </a>
          <div id="modal-error"></div>
        </div>
      </div>
    </div>
  </div>
  </body>
</html>
